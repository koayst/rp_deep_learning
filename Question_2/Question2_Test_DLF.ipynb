{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 400px; height: 160px;\">\n",
    "    <img src=\"rplogo_small.png\" width=\"100%\" height=\"100%\" align=\"left\">\n",
    "</div>\n",
    "\n",
    "###     TIPP - AAI Assignement (Deep Learning Fundamentals)<br>Due Date: 21 February 2020\n",
    "###     Submitted By: <u>KOAY</u> SENG TIAN<br>Email: sengtian@yahoo.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (Testing #1 & Testing #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# set verbose=0 the skip the charts and other information\n",
    "# set verbose=1 to see chart and other information\n",
    "#verbose=0\n",
    "verbose=1\n",
    "\n",
    "# uncomment one of the 2 lines to test either datatest.txt or datatest2.txt\n",
    "testdata_file = 'datatest.txt'\n",
    "#testdata_file = 'datatest2.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run this either as a 1) jupyter note or 2) File -> Download as -> Python (.py) \n",
    "#\n",
    "# 1) Jupyter notebook: \n",
    "#    Settings: 1) set verbose (see above) to either 0 (no charts) or 1 (charts and other information)\n",
    "#              2) comment / uncomment test_datafile to use datatest.txt or datatest2.txt to test the model\n",
    "#\n",
    "# 2) Python script (.py):\n",
    "#        1) open a terminal (command prompt in windows that has python interpreter)\n",
    "#        2) python Question2_Test_DLF.py -h\n",
    "# \n",
    "#           usage: Question #2 Testing [-h] [-v VERBOSE] [-t TEST]\n",
    "#\n",
    "#           optional arguments:\n",
    "#              -h, --help            show this help message and exit\n",
    "#              -v VERBOSE, --verbose VERBOSE\n",
    "#                                   turn on or off verbose mode (default: 1)\n",
    "#              -t TEST, --test TEST  (0) for datatest.txt and (1) datatest1.txt\n",
    "#        3) Example: python Question2_Test_DLF.py -v 0 -t 1 OR\n",
    "#                    python Question2_Test_DLF.py -v 1 -t 2\n",
    "#\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    ap = argparse.ArgumentParser('Question #2 Testing')\n",
    "    ap.add_argument('-v', '--verbose', default='0', type=int, help='turn off(0, default) or on(1) verbose mode')\n",
    "    ap.add_argument('-t', '--test', default='0', type=int, help='(0, default) for datatest.txt and (1) datatest1.txt')\n",
    "\n",
    "    args = vars (ap.parse_args())\n",
    "\n",
    "    verbose = 0\n",
    "    if args.get('verbose') == 1:\n",
    "        verbose=1\n",
    "        \n",
    "    if args.get('test') == 1:\n",
    "        testdata_file = 'datatest2.txt'\n",
    "        \n",
    "    print('Verbose=', verbose, ' Test data file=', testdata_file)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model_filename = 'model.pkl'\n",
    "scaler_filename = 'scaler.pkl'\n",
    "\n",
    "model_dir = os.path.join(os.getcwd(), 'model')\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scaler\n",
    "with open(os.path.join(model_dir, model_filename), 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "    \n",
    "with open(os.path.join(model_dir, scaler_filename), 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir, testdata_file))\n",
    "test_df['date']= pd.to_datetime(test_df['date']) \n",
    "test_df.sort_values(by='date', inplace=True, ascending=True)\n",
    "\n",
    "if verbose==1:\n",
    "    print('Test data shape=', test_df.shape)\n",
    "    print()\n",
    "    print('Training Data:')\n",
    "    print('The time series starts from: ', test_df.date.min())\n",
    "    print('The time series ends on: ', test_df.date.max())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mycharts\n",
    "\n",
    "if verbose==1:\n",
    "    mycharts.chart01(test_df.columns[1:], test_df, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the dat as index\n",
    "test_df = test_df.set_index('date')\n",
    "\n",
    "# shift the data forward by 1\n",
    "# to simulate the effect for future occupancy forecasting \n",
    "test_df = test_df.shift(1)\n",
    "\n",
    "# drop the first row\n",
    "test_df.drop(test_df.head(1).index, inplace=True)\n",
    "\n",
    "if verbose==1:\n",
    "    print('First row was dropped')\n",
    "    print('Shape=', test_df.shape)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.iloc[:,  : -1].copy().to_numpy()\n",
    "y = test_df.iloc[:, -1 ].copy().to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(X)\n",
    "\n",
    "#reshape for LSTM's format samples, timestep and features\n",
    "X = X.reshape(-1, 1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)\n",
    "pred_classes = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes_squeezed = np.squeeze(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('\\n-----------------------------------------------------')\n",
    "print('Test file: ', testdata_file)\n",
    "print('-----------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.crosstab(y, pred_classes_squeezed, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print('\\n-----------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y, pred_classes_squeezed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using datatest.txt, the accuracy is 98%, precision (0=100%, 1.0=96%)\n",
    "# using datatest2.txt, the accuracy is 99%, precision (0=100%, 1.0=96%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
