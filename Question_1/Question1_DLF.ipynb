{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 400px; height: 160px;\">\n",
    "    <img src=\"rplogo_small.png\" width=\"100%\" height=\"100%\" align=\"left\">\n",
    "</div>\n",
    "\n",
    "###     TIPP - AAI Assignement (Deep Learning Fundamentals)<br>Due Date: 21 February 2020\n",
    "###     Submitted By: <u>KOAY</u> SENG TIAN<br>Email: sengtian@yahoo.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TIPP - AAI Assignment (Deep Learning Fundamentals)\n",
    "# Date Due: 21February 2020\n",
    "# Submited By: KOAY SENG TIAN\n",
    "# Email: sengtian@yahoo.com\n",
    "#\n",
    "# GitHub: https://github.com/koayst/rp_deeplearning_assignment\n",
    "#\n",
    "# Note: source of below statement => sonar.names\n",
    "# https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29\n",
    "# Gorman and Sejnowski further report that a nearest neighbor classifier on\n",
    "# the same data gave an 82.7% probability of correct classification.\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import xticks\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 210)\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337)\n",
    "\n",
    "# verbose mode - 0=show little, 1=show more like charts\n",
    "verbose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    filedir = os.path.join(os.getcwd(), 'data')\n",
    "    mines_filename = 'sonar.mines'\n",
    "    rocks_filename = 'sonar.rocks'\n",
    "    sonar_filename = 'sonar.all-data'\n",
    "\n",
    "    # load the data file\n",
    "    file = os.path.join(filedir, sonar_filename)\n",
    "    df = pd.read_csv(file, sep=',', header=None)\n",
    "    \n",
    "    # create the header for the dataframe\n",
    "    # the header starts with 'ANG' followed by a number\n",
    "    header = [f\"ANG{x:02d}\" for x in range(0, df.shape[1])]\n",
    "    df.columns = header\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_data_analysis(df):\n",
    "    print('Any null ?', end=' ')\n",
    "    print(df.isnull().values.any())\n",
    "    print()\n",
    "    print('NULL count in each column:')\n",
    "    print(df.isnull().sum())\n",
    "    print()\n",
    "    print('Any NaN ?', end=' ')\n",
    "    print(sonar_df.isna().any().any())\n",
    "    print()\n",
    "    print('ZERO count in each column:')\n",
    "    # columns 42 to 59 have 0 values, but it is still OK\n",
    "    # as the document said 'each pattern is a set of 60 \n",
    "    # numbers in the range 0.0 to 1.0 [sonar.names]\n",
    "    print(df.eq(0).sum())\n",
    "    print()\n",
    "    \n",
    "    # True if the dtype is object (categorical), otherwise False\n",
    "    mask = sonar_df.dtypes == np.object\n",
    "    # Extract column names that are categorical\n",
    "    categorical_cols = sonar_df.columns[mask]\n",
    "    print('What are the categorical column(s)?', end=' ')\n",
    "    print(categorical_cols)\n",
    "    print()\n",
    "   \n",
    "    # Extract categorical data\n",
    "    categorical_data = sonar_df.select_dtypes(include=['object']).copy()\n",
    "    \n",
    "    # Count the number of cateory for each column\n",
    "    print('Unique value count of categorical columns:')\n",
    "    unique_values_counts = (categorical_data.apply(lambda x: x.nunique()).sort_values(ascending=False))\n",
    "    print(unique_values_counts)\n",
    "    print()\n",
    "    \n",
    "    print('Unique value of categorical columns:')\n",
    "    print(categorical_data.apply(pd.Series.value_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charts(df):\n",
    "    df.plot.box(figsize=(12,7))\n",
    "    plt.xticks(np.arange(0, 61, 5.0), [f\"ANG{x:02d}\" for x in range(0, 61, 5)], rotation=45)\n",
    "    plt.title('Boxplot for all 60 Angles')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_df = load_data()\n",
    "sonar_df.shape\n",
    "\n",
    "if verbose==1:\n",
    "    print(sonar_df.head())\n",
    "    print(sonar_df.tail())\n",
    "    print(sonar_df.info())\n",
    "\n",
    "    charts(sonar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if verbose==1:\n",
    "    exploratory_data_analysis(sonar_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sonar_df.loc[:, sonar_df.columns != 'ANG60'].copy()\n",
    "y = sonar_df.loc[:, 'ANG60'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform label encoding on Y\n",
    "lbl_encoder = LabelEncoder()\n",
    "y_encoded = lbl_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded)\n",
    "\n",
    "# standard scaling\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train = std_scaler.transform(X_train)\n",
    "X_test = std_scaler.transform (X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the Artifical Neuro Network\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(32, activation='relu', input_shape=(60,)))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use stochastic gradient descent as optimizer\n",
    "sgd = SGD(lr = 0.01, momentum = 0.8, decay = 0.01, nesterov = True)\n",
    "network.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 132 samples, validate on 34 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SengTian\\Anaconda3\\envs\\tf1.15\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.9876 - acc: 0.4545 - val_loss: 0.8108 - val_acc: 0.4412\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 104us/step - loss: 0.7712 - acc: 0.5076 - val_loss: 0.6433 - val_acc: 0.6471\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.6455 - acc: 0.6212 - val_loss: 0.5561 - val_acc: 0.6471\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 129us/step - loss: 0.5801 - acc: 0.6818 - val_loss: 0.5086 - val_acc: 0.7353\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 93us/step - loss: 0.5410 - acc: 0.7197 - val_loss: 0.4820 - val_acc: 0.7059\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.5135 - acc: 0.7500 - val_loss: 0.4599 - val_acc: 0.7353\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 129us/step - loss: 0.4903 - acc: 0.7727 - val_loss: 0.4431 - val_acc: 0.8235\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.4714 - acc: 0.8030 - val_loss: 0.4296 - val_acc: 0.8235\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.4545 - acc: 0.8182 - val_loss: 0.4174 - val_acc: 0.8235\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.4403 - acc: 0.8182 - val_loss: 0.4077 - val_acc: 0.8235\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.4256 - acc: 0.8258 - val_loss: 0.3992 - val_acc: 0.8235\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.4129 - acc: 0.8333 - val_loss: 0.3915 - val_acc: 0.8235\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.4021 - acc: 0.8561 - val_loss: 0.3849 - val_acc: 0.8824\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.3916 - acc: 0.8636 - val_loss: 0.3784 - val_acc: 0.8824\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.3823 - acc: 0.8939 - val_loss: 0.3726 - val_acc: 0.8824\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3733 - acc: 0.8939 - val_loss: 0.3673 - val_acc: 0.8824\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.3647 - acc: 0.8939 - val_loss: 0.3624 - val_acc: 0.9118\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3572 - acc: 0.9015 - val_loss: 0.3575 - val_acc: 0.8824\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3498 - acc: 0.9015 - val_loss: 0.3535 - val_acc: 0.8824\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.3432 - acc: 0.9167 - val_loss: 0.3505 - val_acc: 0.8824\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3372 - acc: 0.9167 - val_loss: 0.3480 - val_acc: 0.8824\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.3307 - acc: 0.9242 - val_loss: 0.3454 - val_acc: 0.8824\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3245 - acc: 0.9318 - val_loss: 0.3430 - val_acc: 0.8824\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.3196 - acc: 0.9318 - val_loss: 0.3408 - val_acc: 0.8824\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.3142 - acc: 0.9394 - val_loss: 0.3383 - val_acc: 0.9118\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.3088 - acc: 0.9394 - val_loss: 0.3360 - val_acc: 0.9118\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.3039 - acc: 0.9394 - val_loss: 0.3335 - val_acc: 0.9118\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2991 - acc: 0.9470 - val_loss: 0.3310 - val_acc: 0.9118\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2949 - acc: 0.9470 - val_loss: 0.3289 - val_acc: 0.9118\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.2903 - acc: 0.9470 - val_loss: 0.3265 - val_acc: 0.9118\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.2861 - acc: 0.9545 - val_loss: 0.3246 - val_acc: 0.9118\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2825 - acc: 0.9545 - val_loss: 0.3227 - val_acc: 0.9118\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.2788 - acc: 0.9470 - val_loss: 0.3210 - val_acc: 0.9118\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2743 - acc: 0.9545 - val_loss: 0.3190 - val_acc: 0.9118\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2711 - acc: 0.9545 - val_loss: 0.3173 - val_acc: 0.9118\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.2676 - acc: 0.9545 - val_loss: 0.3161 - val_acc: 0.9118\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2641 - acc: 0.9545 - val_loss: 0.3153 - val_acc: 0.9118\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2607 - acc: 0.9545 - val_loss: 0.3142 - val_acc: 0.9118\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.2808 - acc: 0.933 - 0s 114us/step - loss: 0.2577 - acc: 0.9545 - val_loss: 0.3130 - val_acc: 0.9118\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2546 - acc: 0.9545 - val_loss: 0.3118 - val_acc: 0.9118\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2516 - acc: 0.9545 - val_loss: 0.3099 - val_acc: 0.9118\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2488 - acc: 0.9545 - val_loss: 0.3082 - val_acc: 0.9118\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2461 - acc: 0.9545 - val_loss: 0.3068 - val_acc: 0.9118\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2434 - acc: 0.9545 - val_loss: 0.3057 - val_acc: 0.9118\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2408 - acc: 0.9545 - val_loss: 0.3044 - val_acc: 0.9118\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 106us/step - loss: 0.2382 - acc: 0.9545 - val_loss: 0.3030 - val_acc: 0.9118\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2356 - acc: 0.9545 - val_loss: 0.3020 - val_acc: 0.9118\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 91us/step - loss: 0.2334 - acc: 0.9545 - val_loss: 0.3008 - val_acc: 0.9118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2310 - acc: 0.9545 - val_loss: 0.2995 - val_acc: 0.9118\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2286 - acc: 0.9545 - val_loss: 0.2985 - val_acc: 0.9118\n",
      "\n",
      "42/42 [==============================] - 0s 95us/step\n",
      "\n",
      "test_acc: 0.8809523837906974\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=30, shuffle=True, verbose=1)\n",
    "\n",
    "print()\n",
    "test_loss, test_acc = network.evaluate(X_test, y_test)\n",
    "\n",
    "print()\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above, the test accuracy is ~88%\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162ca3d8248>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162ca3cf408>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x162ca3ea288>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162ca3f5d48>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162ca3f5d88>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x162ca3ff988>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(11,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "#draw a chart to show validation vs training losses\n",
    "ax1.plot(epochs, loss_values, 'r--', label='Training loss')\n",
    "ax1.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "ax1.title.set_text('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# draw a chart to show validation vs training accuracy\n",
    "ax2.plot(epochs, acc_values, 'r--', label='Training acc')\n",
    "ax2.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "ax2.title.set_text('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
